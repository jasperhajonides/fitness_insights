{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "327bb92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install sqlalchemy-cockroachdb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adb73e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "root_path = '/Users/jasperhajonides/Documents/FUN/gpt_fitness_coach/'\n",
    "os.chdir(root_path)\n",
    "\n",
    "from fitness_insights.extraction.fit_import import LoadFitFiles\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47373e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "import tempfile\n",
    "import boto3\n",
    "import psycopg2\n",
    "import os\n",
    "import fitparse\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class FitModel(BaseModel):\n",
    "    id: int\n",
    "    fit_title: str\n",
    "    fit_url: str\n",
    "\n",
    "def download_file(bucket, key, filename):\n",
    "    s3 = boto3.resource('s3')\n",
    "    s3.Bucket(bucket).download_file(key, filename)\n",
    "\n",
    "def sample_urls_postgres():\n",
    "    # retrieve files\n",
    "    conn = psycopg2.connect(\n",
    "        database=\"exampledb\", \n",
    "        user=\"docker\", \n",
    "        password=\"docker\",\n",
    "        host=\"0.0.0.0\"\n",
    "    )\n",
    "\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"SELECT * FROM fitfile ORDER BY id DESC\")\n",
    "    rows = cur.fetchall()\n",
    "\n",
    "    formatted_files = []\n",
    "    for row in rows:\n",
    "        formatted_files.append(\n",
    "            FitModel(id=row[0], fit_title=row[1], fit_url= row[2])\n",
    "        )\n",
    "\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    \n",
    "    return formatted_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d52eb055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2023-06-23-12-56-43.fit\n",
      "https://jhajonides-storage.s3.eu-west-2.amazonaws.com/FitFiles/2023-06-23-12-56-43.fit\n",
      "1\n",
      "2023-06-22-12-11-17.fit\n",
      "https://jhajonides-storage.s3.eu-west-2.amazonaws.com/FitFiles/2023-06-22-12-11-17.fit\n",
      "0\n",
      "2023-06-21-18-24-20.fit\n",
      "https://jhajonides-storage.s3.eu-west-2.amazonaws.com/FitFiles/2023-06-21-18-24-20.fit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "formatted_files = sample_urls_postgres()\n",
    "\n",
    "# Create a session using your AWS credentials\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id='AKIA36VGDUPBPTRBT5UD',\n",
    "    aws_secret_access_key='u1W9PJv9q/B9wxuEmbN4hVStUs+KYN7punjhPWro',\n",
    "    region_name='eu-west-2'# replace with the region where your bucket is located\n",
    ")\n",
    "\n",
    "s3 = session.client('s3')\n",
    "\n",
    "# Specify the bucket and the file key\n",
    "bucket_name = 'jhajonides-storage'\n",
    "\n",
    "df_all = pd.DataFrame()\n",
    "for fit_model in formatted_files:\n",
    "    print(fit_model.id)\n",
    "    print(fit_model.fit_title)\n",
    "    print(fit_model.fit_url)\n",
    "\n",
    "    key = fit_model.fit_url.split('amazonaws.com/')[1] # 'foldername/filename'\n",
    "\n",
    "    # Specify local path where you want to download the file\n",
    "    local_file_path = '2023-06-21-18-24-20.fit'\n",
    "\n",
    "\n",
    "    # Create a temporary file\n",
    "    fd, path = tempfile.mkstemp()\n",
    "\n",
    "    try:\n",
    "        # Download file to the temporary file\n",
    "        s3.download_file(bucket_name, key, path)\n",
    "\n",
    "        fitfile = fitparse.FitFile(path)\n",
    "\n",
    "        data = []\n",
    "        # Iterate through all the messages in the fit file\n",
    "        for dictionary in fitfile.messages:\n",
    "            # Extract the values from each message and append to the data list\n",
    "            values = dictionary.get_values()\n",
    "            data.append(values)\n",
    "\n",
    "        # Convert the list of dictionaries into a DataFrame\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        # Filter out columns with names that start with 'unknown'\n",
    "        df = df.filter(regex=r'^(?!unknown)')\n",
    "\n",
    "        # Obtain the sport from the sport column and add to the file name\n",
    "        sport = next(item for item in df.sport.unique() if isinstance(item, str))\n",
    "        df['file'] = fit_model.fit_url.split('FitFiles/')[1]\n",
    "        df['user'] = 'jasperhajonides'\n",
    "\n",
    "        df_all = pd.concat([df_all, df])\n",
    "\n",
    "    finally:\n",
    "        # Always clean up the temporary file, whether the download succeeded or not\n",
    "        os.close(fd)\n",
    "        os.remove(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33323a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitfile = await download_and_parse_fitfile('jhajonides-storage', file_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48f9b0ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'app' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 37\u001b[0m\n\u001b[1;32m     32\u001b[0m         df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m fit_model\u001b[38;5;241m.\u001b[39mfit_url\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFitFiles/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;129m@app\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/fitfiles\u001b[39m\u001b[38;5;124m\"\u001b[39m, response_model\u001b[38;5;241m=\u001b[39mList[FitModel])\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_plot_fitfiles\u001b[39m():\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# Connect to the database\u001b[39;00m\n\u001b[1;32m     40\u001b[0m     conn \u001b[38;5;241m=\u001b[39m psycopg2\u001b[38;5;241m.\u001b[39mconnect(\n\u001b[1;32m     41\u001b[0m         database\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexampledb\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     42\u001b[0m         user\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocker\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     43\u001b[0m         password\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocker\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     44\u001b[0m         host\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.0.0.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     45\u001b[0m     )\n\u001b[1;32m     47\u001b[0m     cur \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mcursor()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'app' is not defined"
     ]
    }
   ],
   "source": [
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "import base64\n",
    "\n",
    "async def download_and_parse_fitfile(bucket: str, file_key: str):\n",
    "    \n",
    "    session = boto3.Session(\n",
    "        aws_access_key_id='AKIA36VGDUPBPTRBT5UD',\n",
    "        aws_secret_access_key='u1W9PJv9q/B9wxuEmbN4hVStUs+KYN7punjhPWro',\n",
    "        region_name='eu-west-2'# replace with the region where your bucket is located\n",
    "    )\n",
    "\n",
    "    s3 = session.client('s3')\n",
    "    \n",
    "    with tempfile.TemporaryFile() as fp:\n",
    "        print(fp)\n",
    "        s3.download_fileobj(bucket, fit_model.fit_url.split('amazonaws.com/')[1], fp)\n",
    "        fp.seek(0)  # reset file pointer to the beginning\n",
    "        fitfile = fitparse.FitFile(fp)\n",
    "        \n",
    "        # You can create a dictionary of the data you need here\n",
    "        # For example:\n",
    "        data = []\n",
    "        # Iterate through all the messages in the fit file\n",
    "        for dictionary in fitfile.messages:\n",
    "            # Extract the values from each message and append to the data list\n",
    "            values = dictionary.get_values()\n",
    "            data.append(values)\n",
    "\n",
    "        # Convert the list of dictionaries into a DataFrame\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "\n",
    "        return df\n",
    "    \n",
    "@app.get(\"/fitfiles\", response_model=List[FitModel])\n",
    "async def get_plot_fitfiles():\n",
    "    # Connect to the database\n",
    "    conn = psycopg2.connect(\n",
    "        database=\"exampledb\", \n",
    "        user=\"docker\", \n",
    "        password=\"docker\",\n",
    "        host=\"0.0.0.0\"\n",
    "    )\n",
    "\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"SELECT * FROM fitfile ORDER BY id DESC\")\n",
    "    rows = cur.fetchall()\n",
    "\n",
    "    formatted_files = []\n",
    "    for row in rows:\n",
    "        file_id = row[0]\n",
    "        file_title = row[1]\n",
    "        file_url = row[2]\n",
    "\n",
    "        # download to temporary file and parse\n",
    "        df = await download_and_parse_fitfile('jhajonides-storage', file_url)\n",
    "        \n",
    "        # create plot\n",
    "        plt.figure()\n",
    "        plt.plot(df['heart_rate'].dropna())  # Adjust this line based on the actual structure of your fitfile data\n",
    "        plt.title(f\"File: {file_title}\")\n",
    "        \n",
    "        # Save plot to BytesIO object\n",
    "        img = BytesIO()\n",
    "        plt.savefig(img, format='png')\n",
    "        img.seek(0)\n",
    "        plt.close()\n",
    "\n",
    "        # Encode image to base64\n",
    "        img_b64 = base64.b64encode(img.read()).decode()\n",
    "\n",
    "        formatted_files.append(\n",
    "            FitModel(id=file_id, fit_title=file_title, fit_url=file_url, plot=img_b64)\n",
    "        )\n",
    "\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    return formatted_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e08a1192",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_activities = df_all.loc[df_all.trigger == 'activity_end'].dropna(axis=1,how='all') \n",
    "\n",
    "df1 = df[['timestamp','heart_rate','file']].dropna() #.head(20)\n",
    "# df2 = df[['timestamp','heart_rate','file']].dropna().tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d413de7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m dbConnection \u001b[38;5;241m=\u001b[39m alchemyEngine\u001b[38;5;241m.\u001b[39mconnect();\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Create new table \"your_table_name\" with df1\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m df1\u001b[38;5;241m.\u001b[39mto_sql(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_table\u001b[39m\u001b[38;5;124m'\u001b[39m, dbConnection, if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m df_activities\u001b[38;5;241m.\u001b[39mto_sql(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msummary_table\u001b[39m\u001b[38;5;124m'\u001b[39m, dbConnection, if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Append df2 to \"your_table_name\"\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# df2.to_sql('test_table', dbConnection, if_exists='append')\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Close the database connection\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df1' is not defined"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Create an engine instance\n",
    "alchemyEngine  = create_engine('postgresql+psycopg2://docker:docker@localhost:5432/exampledb', pool_recycle=3600)\n",
    "\n",
    "# Connect to PostgreSQL server\n",
    "dbConnection = alchemyEngine.connect();\n",
    "\n",
    "# Create new table \"your_table_name\" with df1\n",
    "df1.to_sql('test_table', dbConnection, if_exists='replace')\n",
    "df_activities.to_sql('summary_table', dbConnection, if_exists='replace')\n",
    "\n",
    "# Append df2 to \"your_table_name\"\n",
    "# df2.to_sql('test_table', dbConnection, if_exists='append')\n",
    "\n",
    "# Close the database connection\n",
    "dbConnection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82c172a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>event</th>\n",
       "      <th>event_type</th>\n",
       "      <th>sport</th>\n",
       "      <th>sub_sport</th>\n",
       "      <th>max_heart_rate</th>\n",
       "      <th>start_time</th>\n",
       "      <th>start_position_lat</th>\n",
       "      <th>start_position_long</th>\n",
       "      <th>...</th>\n",
       "      <th>first_lap_index</th>\n",
       "      <th>num_laps</th>\n",
       "      <th>pool_length</th>\n",
       "      <th>total_training_effect</th>\n",
       "      <th>trigger</th>\n",
       "      <th>pool_length_unit</th>\n",
       "      <th>total_anaerobic_training_effect</th>\n",
       "      <th>file</th>\n",
       "      <th>total_cycles</th>\n",
       "      <th>avg_cadence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2758</td>\n",
       "      <td>2023-06-23 12:16:09</td>\n",
       "      <td>lap</td>\n",
       "      <td>stop</td>\n",
       "      <td>running</td>\n",
       "      <td>generic</td>\n",
       "      <td>159.0</td>\n",
       "      <td>2023-06-23 11:56:43</td>\n",
       "      <td>614874284.0</td>\n",
       "      <td>-2328392.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.7</td>\n",
       "      <td>activity_end</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2023-06-23-12-56-43.fit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6691</td>\n",
       "      <td>2023-06-22 12:37:39</td>\n",
       "      <td>lap</td>\n",
       "      <td>stop</td>\n",
       "      <td>training</td>\n",
       "      <td>strength_training</td>\n",
       "      <td>164.0</td>\n",
       "      <td>2023-06-22 11:11:17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.3</td>\n",
       "      <td>activity_end</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2023-06-22-12-11-17.fit</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10338</td>\n",
       "      <td>2023-06-21 18:53:20</td>\n",
       "      <td>lap</td>\n",
       "      <td>stop</td>\n",
       "      <td>swimming</td>\n",
       "      <td>lap_swimming</td>\n",
       "      <td>170.0</td>\n",
       "      <td>2023-06-21 17:24:19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>activity_end</td>\n",
       "      <td>metric</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2023-06-21-18-24-20.fit</td>\n",
       "      <td>1523.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index           timestamp event event_type     sport          sub_sport  \\\n",
       "0   2758 2023-06-23 12:16:09   lap       stop   running            generic   \n",
       "1   6691 2023-06-22 12:37:39   lap       stop  training  strength_training   \n",
       "2  10338 2023-06-21 18:53:20   lap       stop  swimming       lap_swimming   \n",
       "\n",
       "   max_heart_rate          start_time  start_position_lat  \\\n",
       "0           159.0 2023-06-23 11:56:43         614874284.0   \n",
       "1           164.0 2023-06-22 11:11:17                 NaN   \n",
       "2           170.0 2023-06-21 17:24:19                 NaN   \n",
       "\n",
       "   start_position_long  ...  first_lap_index  num_laps  pool_length  \\\n",
       "0           -2328392.0  ...              0.0       5.0          NaN   \n",
       "1                  NaN  ...              0.0       1.0          NaN   \n",
       "2                  NaN  ...              0.0      78.0         25.0   \n",
       "\n",
       "   total_training_effect       trigger pool_length_unit  \\\n",
       "0                    2.7  activity_end             None   \n",
       "1                    2.3  activity_end             None   \n",
       "2                    3.2  activity_end           metric   \n",
       "\n",
       "  total_anaerobic_training_effect                     file total_cycles  \\\n",
       "0                             0.7  2023-06-23-12-56-43.fit          NaN   \n",
       "1                             0.1  2023-06-22-12-11-17.fit         33.0   \n",
       "2                             0.1  2023-06-21-18-24-20.fit       1523.0   \n",
       "\n",
       "  avg_cadence  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2        29.0  \n",
       "\n",
       "[3 rows x 49 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create an engine instance\n",
    "alchemyEngine  = create_engine('postgresql+psycopg2://docker:docker@localhost:5432/exampledb', pool_recycle=3600)\n",
    "\n",
    "# Connect to PostgreSQL server\n",
    "dbConnection = alchemyEngine.connect();\n",
    "\n",
    "# Execute the query and fetch all the rows where heart_rate is less than 120\n",
    "# dfx = pd.read_sql_query(\"SELECT * FROM test_table WHERE heart_rate < 140\", dbConnection)\n",
    "dfax = pd.read_sql_query(\"SELECT * FROM summary_table\", dbConnection)\n",
    "\n",
    "# Close the database connection\n",
    "dbConnection.close()\n",
    "\n",
    "display(dfax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56d2aad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7540.01"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfax.total_distance.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ded3557b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_time': 146.9, 'total_distsance': 7.54}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_vals = {}\n",
    "dict_vals['total_time'] = np.round(dfax.total_timer_time.sum()/60,1)\n",
    "dict_vals['total_distsance'] = dfax.total_distance.sum().round(1)/1e3\n",
    "\n",
    "dict_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53da74c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'timestamp',\n",
       " 'event',\n",
       " 'event_type',\n",
       " 'sport',\n",
       " 'sub_sport',\n",
       " 'max_heart_rate',\n",
       " 'start_time',\n",
       " 'start_position_lat',\n",
       " 'start_position_long',\n",
       " 'total_elapsed_time',\n",
       " 'total_timer_time',\n",
       " 'total_distance',\n",
       " 'total_strides',\n",
       " 'avg_left_power_phase',\n",
       " 'avg_left_power_phase_peak',\n",
       " 'avg_right_power_phase',\n",
       " 'avg_right_power_phase_peak',\n",
       " 'avg_power_position',\n",
       " 'max_power_position',\n",
       " 'message_index',\n",
       " 'total_calories',\n",
       " 'total_ascent',\n",
       " 'total_descent',\n",
       " 'avg_stroke_distance',\n",
       " 'num_active_lengths',\n",
       " 'avg_heart_rate',\n",
       " 'avg_running_cadence',\n",
       " 'max_running_cadence',\n",
       " 'avg_temperature',\n",
       " 'max_temperature',\n",
       " 'avg_fractional_cadence',\n",
       " 'max_fractional_cadence',\n",
       " 'avg_cadence_position',\n",
       " 'max_cadence_position',\n",
       " 'nec_lat',\n",
       " 'nec_long',\n",
       " 'swc_lat',\n",
       " 'swc_long',\n",
       " 'first_lap_index',\n",
       " 'num_laps',\n",
       " 'pool_length',\n",
       " 'total_training_effect',\n",
       " 'trigger',\n",
       " 'pool_length_unit',\n",
       " 'total_anaerobic_training_effect',\n",
       " 'file',\n",
       " 'total_cycles',\n",
       " 'avg_cadence']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dfax.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7912c356",
   "metadata": {},
   "source": [
    "# cockroach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32918f93",
   "metadata": {},
   "source": [
    "### create a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c29f6758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'heart_rate_table' already exists.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "\n",
    "\n",
    "# create an engine instance\n",
    "alchemyEngine = create_engine('cockroachdb://jasper:PuJW-gU4tv23fuhRIdBMxA@sticky-zokor-9372.8nj.cockroachlabs.cloud:26257/defaultdb', pool_recycle=3600)\n",
    "\n",
    "# connect to the PostgreSQL server\n",
    "postgreSQLConnection = alchemyEngine.connect()\n",
    "dfHr = pd.read_sql_query(\"SELECT * FROM heart_rate_table WHERE heart_rate < 140\", postgreSQLConnection)\n",
    "\n",
    "try:\n",
    "    frame = df1.to_sql('heart_rate_table', postgreSQLConnection, if_exists='fail')\n",
    "except ValueError as vx:\n",
    "    print(vx)\n",
    "except Exception as ex:  \n",
    "    print(ex)\n",
    "else:\n",
    "    print(\"PostgreSQL Table has been created successfully.\")\n",
    "finally:\n",
    "    postgreSQLConnection.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5401c5",
   "metadata": {},
   "source": [
    "### append to existing table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e9f1625",
   "metadata": {},
   "outputs": [],
   "source": [
    "with alchemyEngine.connect() as postgreSQLConnection:\n",
    "    df2.to_sql('heart_rate_table', postgreSQLConnection, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e39997",
   "metadata": {},
   "source": [
    "### query a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24a804b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    index           timestamp  heart_rate\n",
      "0    22.0 2023-06-21 17:24:20        95.0\n",
      "1    24.0 2023-06-21 17:24:21        94.0\n",
      "2    26.0 2023-06-21 17:24:22        97.0\n",
      "3    28.0 2023-06-21 17:24:23        97.0\n",
      "4    30.0 2023-06-21 17:24:24        96.0\n",
      "5    32.0 2023-06-21 17:24:25        95.0\n",
      "6    34.0 2023-06-21 17:24:26        97.0\n",
      "7    36.0 2023-06-21 17:24:27        96.0\n",
      "8    38.0 2023-06-21 17:24:28        99.0\n",
      "9    40.0 2023-06-21 17:24:29        99.0\n",
      "10   42.0 2023-06-21 17:24:30        97.0\n",
      "11   44.0 2023-06-21 17:24:31       100.0\n",
      "12   46.0 2023-06-21 17:24:32       101.0\n",
      "13   48.0 2023-06-21 17:24:33       101.0\n",
      "14   50.0 2023-06-21 17:24:34       102.0\n",
      "15   52.0 2023-06-21 17:24:35       102.0\n",
      "16   54.0 2023-06-21 17:24:36       103.0\n",
      "17   56.0 2023-06-21 17:24:37       104.0\n",
      "18   58.0 2023-06-21 17:24:38       103.0\n",
      "19   60.0 2023-06-21 17:24:39       102.0\n",
      "20    NaN 2023-06-21 18:40:13       133.0\n",
      "21    NaN 2023-06-21 18:40:14       132.0\n",
      "22    NaN 2023-06-21 18:40:15       131.0\n",
      "23    NaN 2023-06-21 18:40:16       130.0\n",
      "24    NaN 2023-06-21 18:40:17       130.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# connect to the PostgreSQL server\n",
    "with alchemyEngine.connect() as postgreSQLConnection:\n",
    "    # query to fetch all rows where 'heart_rate' < 105\n",
    "    query = \"SELECT * FROM heart_rate_table \" # WHERE heart_rate < 190\n",
    "    result = pd.read_sql_query(query, postgreSQLConnection)\n",
    "\n",
    "# 'result' is a DataFrame that holds the result of the query\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
